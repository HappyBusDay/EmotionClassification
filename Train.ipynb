{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgJfWRB9QleO"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJXxUVKSnx2S"
      },
      "outputs": [],
      "source": [
        "! pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fzvQU3lAdnm_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import random\n",
        "import os\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tqdm.notebook import tqdm\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModel\n",
        "from torch.optim import AdamW\n",
        "import torch.optim as optim\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SO7GM91VQzgA"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiZ6FYECQ93c"
      },
      "source": [
        "## Hyperparameter Setting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05nBnq4EfSs7"
      },
      "outputs": [],
      "source": [
        "CFG = {\n",
        "    'EPOCHS': 50,\n",
        "    'LEARNING_RATE':3e-6,\n",
        "    'BATCH_SIZE':8,\n",
        "    'SEED':41\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPubv2UZRRpv"
      },
      "source": [
        "## Fixed RandomSeed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9uNDC9vlRX22"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_everything(CFG['SEED']) # Seed 고정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mtvfLD_RfHs"
      },
      "source": [
        "## Data Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8fYn35O-6ak"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv(model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__FgKrhLkR7W"
      },
      "source": [
        "## Label encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ZYmuaoBkR7W"
      },
      "outputs": [],
      "source": [
        "le = LabelEncoder()\n",
        "le=le.fit(train['Target'])\n",
        "train['Target']=le.transform(train['Target'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erqF3l3LSFx7"
      },
      "source": [
        "## Train/Validation split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PcTjaXGRrdG",
        "outputId": "5c4c13b2-442a-47cf-c020-75f331f7b514"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9725\n",
            "264\n"
          ]
        }
      ],
      "source": [
        "valid=train[train['Dialogue_ID'].isin([i for i in range(1016,1039)])].reset_index(drop=True)\n",
        "train=train[~train['Dialogue_ID'].isin([i for i in range(1016,1039)])].reset_index(drop=True)\n",
        "\n",
        "train_len=len(train)\n",
        "val_len=len(valid)\n",
        "\n",
        "print(train_len)\n",
        "print(val_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26ZtQWpJqGxb"
      },
      "outputs": [],
      "source": [
        "train = CustomDataset(train, mode = \"train\")\n",
        "valid = CustomDataset(valid, mode = \"train\")\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(train, batch_size= CFG['BATCH_SIZE'], shuffle=True)\n",
        "val_dataloader = torch.utils.data.DataLoader(valid, batch_size= CFG['BATCH_SIZE'], shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3W96rVUTaaq"
      },
      "source": [
        "## Tokenizer Define"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ItgoMXv4TXX9"
      },
      "outputs": [],
      "source": [
        "tokenizers = AutoTokenizer.from_pretrained('tae898/emoberta-base')\n",
        "# tokenizers = AutoTokenizer.from_pretrained('tae898/emoberta-large')\n",
        "# tokenizers = AutoTokenizer.from_pretrained('bhadresh-savani/distilbert-base-uncased-emotion')\n",
        "# tokenizers = AutoTokenizer.from_pretrained('bhadresh-savani/bert-base-uncased-emotion')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fixY8ozVT60m"
      },
      "source": [
        "## CustomDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oNfNtFJlmScu"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "  \n",
        "    def __init__(self, data, mode = \"train\"):\n",
        "        self.dataset = data\n",
        "        self.tokenizer = tokenizers\n",
        "        self.mode = mode\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "  \n",
        "    def __getitem__(self, idx):\n",
        "        text = self.dataset['Utterance'][idx]\n",
        "        inputs = self.tokenizer(text, padding='max_length', max_length = 512, truncation=True, return_tensors=\"pt\")        \n",
        "        input_ids = inputs['input_ids'][0]\n",
        "        attention_mask = inputs['attention_mask'][0]\n",
        "    \n",
        "        if self.mode == \"train\":\n",
        "            y = self.dataset['Target'][idx]\n",
        "            return input_ids, attention_mask, y\n",
        "        else:\n",
        "            return input_ids, attention_mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZeXapo-Ugye"
      },
      "source": [
        "## Model Define"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tGiJObIs71ui"
      },
      "outputs": [],
      "source": [
        "class BaseModel(nn.Module):\n",
        "\n",
        "    def __init__(self, dropout=0.5, num_classes=len(le.classes_)):\n",
        "\n",
        "        super(BaseModel, self).__init__()\n",
        "\n",
        "        self.bert = AutoModel.from_pretrained('tae898/emoberta-base')\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear = nn.Linear(768, num_classes)\n",
        "        self.gelu = nn.GELU()\n",
        "\n",
        "    def forward(self, input_id, mask):\n",
        "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
        "        dropout_output = self.dropout(pooled_output)\n",
        "        linear_output = self.linear(dropout_output)\n",
        "        final_layer = self.gelu(linear_output)\n",
        "\n",
        "        return final_layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEM3ikH6U4gt"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZkUaFs-ywA74"
      },
      "outputs": [],
      "source": [
        "model_path = ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLmC6DvAU6HG"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer, train_loader, test_loader, device):\n",
        "\n",
        "    # model.load_state_dict(torch.load(model_path))\n",
        "    model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "    best_score = 0\n",
        "    best_model = \"None\"\n",
        "\n",
        "    epoch_step = 0\n",
        "\n",
        "    for epoch_num in range(CFG[\"EPOCHS\"]):\n",
        "        \n",
        "        model.train()\n",
        "\n",
        "        train_loss = []\n",
        "\n",
        "        for input_ids, attention_mask, train_label in tqdm(train_loader):\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            train_label = train_label.to(device)\n",
        "            input_id = input_ids.to(device)\n",
        "            mask = attention_mask.to(device)\n",
        "\n",
        "            output = model(input_id, mask)     \n",
        "    \n",
        "            batch_loss = criterion(output, train_label.long()) \n",
        "            train_loss.append(batch_loss.item())\n",
        "            \n",
        "            batch_loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "        epoch_step += 1\n",
        "\n",
        "        val_loss, val_score = validation(model, criterion, test_loader, device)\n",
        "\n",
        "        # scheduler.step(float(np.mean(val_loss)))\n",
        "\n",
        "        print(f'Epoch [{epoch_step}], Train Loss : [{np.mean(train_loss) :.5f}] Val Loss : [{np.mean(val_loss) :.5f}] Val F1 Score : [{val_score:.5f}]')\n",
        "\n",
        "        model_saved_path = './path' + str(epoch_step) + '.pt'\n",
        "\n",
        "        torch.save(model.state_dict(), model_saved_path)\n",
        "\n",
        "        if best_score < val_score:\n",
        "            best_model = model\n",
        "            best_score = val_score\n",
        "        \n",
        "    return best_model                         "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2WA2WfWW1eC"
      },
      "outputs": [],
      "source": [
        "def competition_metric(true, pred):\n",
        "    return f1_score(true, pred, average=\"macro\")\n",
        "\n",
        "def validation(model, criterion, test_loader, device):\n",
        "    model.eval()\n",
        "\n",
        "    val_loss = []\n",
        "    model_preds = []\n",
        "    true_labels = []  \n",
        "    with torch.no_grad():\n",
        "        for input_ids, attention_mask, valid_label in tqdm(test_loader):\n",
        "            valid_label = valid_label.to(device)\n",
        "            input_id = input_ids.to(device)\n",
        "            mask = attention_mask.to(device)\n",
        "\n",
        "            output = model(input_id, mask)\n",
        "    \n",
        "            batch_loss = criterion(output, valid_label.long()) \n",
        "            val_loss.append(batch_loss.item())      \n",
        "            \n",
        "            model_preds += output.argmax(1).detach().cpu().numpy().tolist()\n",
        "            true_labels += valid_label.detach().cpu().numpy().tolist()\n",
        "        val_f1 = competition_metric(true_labels, model_preds)\n",
        "    return val_loss, val_f1    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KOUGrLZLYTW9"
      },
      "outputs": [],
      "source": [
        "model = BaseModel()\n",
        "model.eval()\n",
        "optimizer = torch.optim.AdamW(params = model.parameters(), lr = CFG[\"LEARNING_RATE\"])\n",
        "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode = 'min', factor = 0.1, patience = 1, threshold = 1e-3, verbose = True)\n",
        "\n",
        "infer_model = train(model, optimizer, scheduler, train_dataloader, val_dataloader, device)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "taeyang_torch",
      "language": "python",
      "name": "taeyang_torch"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}